{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e355989",
   "metadata": {},
   "source": [
    "# Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39f0e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define constants\n",
    "DATA_DIR = r'C:\\Mini_Project\\output\\final_data\\data'\n",
    "STRIKES = [0.8, 0.85, 0.9, 0.95, 1.0, 1.05, 1.1, 1.15, 1.2]\n",
    "MATURITIES = [30, 60, 90, 120, 150, 180, 360]\n",
    "START_DATE = datetime(2015, 11, 2)\n",
    "END_DATE = datetime(2025, 10, 31)\n",
    "\n",
    "# Generate the list of dates in the range (closed interval)\n",
    "all_dates = pd.date_range(START_DATE, END_DATE, freq='B')  # Use business days if needed, else use 'D'\n",
    "\n",
    "\n",
    "# Helper function to load options data, concatenate, and filter relevant columns\n",
    "def load_all_options_data(data_dir, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Load all yearly option files and concatenate into one DataFrame.\n",
    "    \"\"\"\n",
    "    all_dfs = []\n",
    "    for year in range(start_date.year, end_date.year + 1):\n",
    "        yearly_folder = os.path.join(data_dir, str(year))\n",
    "        csv_path = os.path.join(yearly_folder, f\"^NDX_options_data_{year}.csv\")\n",
    "        if os.path.exists(csv_path):\n",
    "            df = pd.read_csv(csv_path, parse_dates=['date'])\n",
    "            all_dfs.append(df)\n",
    "    if not all_dfs:\n",
    "        raise FileNotFoundError(\"No options data files found in the requested range.\")\n",
    "    all_data = pd.concat(all_dfs, ignore_index=True)\n",
    "    return all_data\n",
    "\n",
    "# Load all data (it automatically parses dates)\n",
    "options_data = load_all_options_data(DATA_DIR, START_DATE, END_DATE)\n",
    "\n",
    "# Ensure the date column is datetime, and filter for requested date range\n",
    "options_data['date'] = pd.to_datetime(options_data['date'])\n",
    "options_data = options_data[(options_data['date'] >= START_DATE) & (options_data['date'] <= END_DATE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "294d0003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>current_price</th>\n",
       "      <th>strike</th>\n",
       "      <th>relative_strike</th>\n",
       "      <th>maturity_days</th>\n",
       "      <th>maturity_years</th>\n",
       "      <th>option_price</th>\n",
       "      <th>implied_vol</th>\n",
       "      <th>volume</th>\n",
       "      <th>option_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>4703.919922</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.313281</td>\n",
       "      <td>11.0</td>\n",
       "      <td>put</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>4703.919922</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>60</td>\n",
       "      <td>0.164384</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.311558</td>\n",
       "      <td>10.0</td>\n",
       "      <td>put</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>4703.919922</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>90</td>\n",
       "      <td>0.246575</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.310001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>put</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>4703.919922</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>120</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.308700</td>\n",
       "      <td>2.0</td>\n",
       "      <td>put</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>4703.919922</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>150</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.307784</td>\n",
       "      <td>2.0</td>\n",
       "      <td>put</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  current_price  strike  relative_strike  maturity_days  \\\n",
       "0 2015-11-02    4703.919922  3775.0              0.8             30   \n",
       "1 2015-11-02    4703.919922  3775.0              0.8             60   \n",
       "2 2015-11-02    4703.919922  3775.0              0.8             90   \n",
       "3 2015-11-02    4703.919922  3775.0              0.8            120   \n",
       "4 2015-11-02    4703.919922  3775.0              0.8            150   \n",
       "\n",
       "   maturity_years  option_price  implied_vol  volume option_type  \n",
       "0        0.082192           2.2     0.313281    11.0         put  \n",
       "1        0.164384           4.5     0.311558    10.0         put  \n",
       "2        0.246575           9.4     0.310001     2.0         put  \n",
       "3        0.328767          28.5     0.308700     2.0         put  \n",
       "4        0.410959          28.5     0.307784     2.0         put  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6bebb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the time series of log-returns for each (strike, maturity) combination\n",
    "log_returns_dict = {}\n",
    "for k in STRIKES:\n",
    "    for t in MATURITIES:\n",
    "        # Select rows for this strike/maturity\n",
    "        mask = (options_data['relative_strike'] == k) & (options_data['maturity_days'] == t)\n",
    "        df_slice = options_data[mask].copy()\n",
    "        # Sort by date to ensure chronological order\n",
    "        df_slice = df_slice.sort_values('date')\n",
    "        # Pick the column (e.g. implied_vol or option_price) for returns\n",
    "        # We'll use implied_vol as an example, but you may change to 'option_price' if needed\n",
    "        price_series = df_slice.set_index('date')['implied_vol']\n",
    "        price_series = price_series.loc[~price_series.index.duplicated(keep='first')]\n",
    "        # Compute log returns\n",
    "        log_ret = np.log(price_series).diff().dropna()\n",
    "        # Store as a pandas Series in the dictionary\n",
    "        log_returns_dict[(k, t)] = log_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fdb5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awong1\\AppData\\Local\\Temp\\ipykernel_11596\\3287432748.py:64: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
      "  result = minimize(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strike=0.80, Maturity=30d | mu=0.00837, sigma=0.04965, lambda=0.40077, mu_j=-0.02103, sigma_j=0.19853, success=True\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "keys must be str, int, float, bool or None, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Write params to file after each loop\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(log_filename, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerton_params_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\__init__.py:179\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    173\u001b[39m     iterable = \u001b[38;5;28mcls\u001b[39m(skipkeys=skipkeys, ensure_ascii=ensure_ascii,\n\u001b[32m    174\u001b[39m         check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n\u001b[32m    175\u001b[39m         separators=separators,\n\u001b[32m    176\u001b[39m         default=default, sort_keys=sort_keys, **kw).iterencode(obj)\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\encoder.py:432\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    430\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    434\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\encoder.py:377\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode_dict\u001b[39m\u001b[34m(dct, _current_indent_level)\u001b[39m\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mkeys must be str, int, float, bool or None, \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    378\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first:\n\u001b[32m    380\u001b[39m     first = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: keys must be str, int, float, bool or None, not tuple"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Merton's jump-diffusion log-likelihood for increments\n",
    "def merton_loglike(params, returns):\n",
    "    \"\"\"\n",
    "    params: [mu, sigma, lam, mu_j, sigma_j]\n",
    "    returns: array of log returns\n",
    "    \"\"\"\n",
    "    mu, sigma, lam, mu_j, sigma_j = params\n",
    "\n",
    "    # Physical constraints to keep fit reasonable\n",
    "    if sigma <= 0 or sigma_j <= 0 or lam < 0:\n",
    "        return np.inf  # negative likelihood\n",
    "\n",
    "    # For numerical stability, restrict lambda to small positive if close to zero\n",
    "    lam = max(lam, 1e-12)\n",
    "\n",
    "    # Discretization over possible number of jumps (0, 1, 2, ...)\n",
    "    max_k = 5  # Most probability mass will be in 0-3 jumps per dt\n",
    "\n",
    "    # dt = 1 for daily log returns; generalization: dt\n",
    "    dt = 1.0\n",
    "    prob = 0.0\n",
    "    ll = 0.0\n",
    "    for x in returns:\n",
    "        px = 0.0\n",
    "        for k in range(max_k+1):\n",
    "            # Poisson probability of k jumps\n",
    "            p_k = np.exp(-lam*dt) * (lam*dt)**k / math.factorial(k)\n",
    "            mean = mu*dt + k*mu_j\n",
    "            var = sigma**2*dt + k*sigma_j**2\n",
    "            px += p_k * norm.pdf(x, loc=mean, scale=np.sqrt(var))\n",
    "        # Protect against log(0)\n",
    "        px = max(px, 1e-18)\n",
    "        ll += np.log(px)\n",
    "    return -ll  # negative log-likelihood for minimization\n",
    "\n",
    "# Dictionary for estimated parameters\n",
    "merton_params_dict = {}\n",
    "\n",
    "import json\n",
    "\n",
    "log_filename = \"jump_process_params.log\"\n",
    "\n",
    "for key, returns in log_returns_dict.items():\n",
    "    returns = returns.values\n",
    "    # Initial params: [mu, sigma, lam, mu_j, sigma_j]\n",
    "    mu0 = np.mean(returns)\n",
    "    sigma0 = np.std(returns)\n",
    "    lam0 = 0.1  # initial guess: 0.1 jumps per day\n",
    "    mu_j0 = 0.0\n",
    "    sigma_j0 = 0.2*sigma0 if sigma0 > 0 else 0.01\n",
    "    bounds = [\n",
    "        (None, None),         # mu\n",
    "        (1e-6, None),         # sigma > 0\n",
    "        (0, 2.0),             # lambda >= 0\n",
    "        (None, None),         # mu_j\n",
    "        (1e-6, None),         # sigma_j > 0\n",
    "    ]\n",
    "    x0 = [mu0, sigma0, lam0, mu_j0, sigma_j0]\n",
    "    result = minimize(\n",
    "        merton_loglike, x0, args=(returns,), method='L-BFGS-B', bounds=bounds,\n",
    "        options={'disp': False, 'maxiter': 500}\n",
    "    )\n",
    "    opt_params = result.x\n",
    "    merton_params_dict[key] = {\n",
    "        'mu': opt_params[0],\n",
    "        'sigma': opt_params[1],\n",
    "        'lambda': opt_params[2],\n",
    "        'mu_jump': opt_params[3],\n",
    "        'sigma_jump': opt_params[4],\n",
    "        'success': result.success,\n",
    "        'negloglike': result.fun\n",
    "    }\n",
    "    print(f\"Strike={key[0]:.2f}, Maturity={key[1]:d}d | \"\n",
    "          f\"mu={opt_params[0]:.5f}, sigma={opt_params[1]:.5f}, \"\n",
    "          f\"lambda={opt_params[2]:.5f}, mu_j={opt_params[3]:.5f}, sigma_j={opt_params[4]:.5f}, \"\n",
    "          f\"success={result.success}\")\n",
    "\n",
    "    # Write params to file after each loop\n",
    "    # Convert tuple keys to strings for JSON serialization\n",
    "    json_dict = {f\"{k[0]}_{k[1]}\": v for k, v in merton_params_dict.items()}\n",
    "    with open(log_filename, \"w\") as f:\n",
    "        json.dump(json_dict, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa91c11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
